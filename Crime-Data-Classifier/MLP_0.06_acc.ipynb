{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5f0b45f",
   "metadata": {},
   "source": [
    "# # London Crime MLP Classifier\n",
    "# Predicting **Crime type** using TensorFlow/Keras Multi-Layer Perceptron Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9d153e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-15 01:21:02.577398: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-15 01:21:02.652750: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-15 01:21:04.183710: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "\n",
    "# %%\n",
    "import psutil\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import time\n",
    "import os\n",
    "import io\n",
    "import requests\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, recall_score, confusion_matrix, roc_auc_score, accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, BatchNormalization, Conv1D, GlobalMaxPooling1D, Flatten, Activation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e95dca2",
   "metadata": {},
   "source": [
    "Class Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ca51c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, save_path=\"Model\"):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history[\"accuracy\"])\n",
    "    plt.plot(history.history[\"val_accuracy\"])\n",
    "    plt.title(\"Model accuracy\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend([\"Train\", \"Validation\"], loc=\"upper left\")\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history[\"loss\"])\n",
    "    plt.plot(history.history[\"val_loss\"])\n",
    "    plt.title(\"Model loss\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend([\"Train\", \"Validation\"], loc=\"upper left\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(save_path, \"training_history.png\"))\n",
    "    plt.close()\n",
    "    print(f\"[✓] Saved training history plot to {save_path}/training_history.png\")\n",
    "\n",
    "def save_model_checkpoint(model, epoch_label, save_path=\"Model\"):\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    # Save full model (architecture + weights)\n",
    "    model.save(os.path.join(save_path, f\"model_epoch_{epoch_label}.h5\"))\n",
    "\n",
    "    # Save weights (NEW required naming)\n",
    "    model.save_weights(\n",
    "        os.path.join(save_path, f\"weights_epoch_{epoch_label}.weights.h5\")\n",
    "    )\n",
    "\n",
    "    print(f\"[✓] Saved model at epoch {epoch_label}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097aff64",
   "metadata": {},
   "source": [
    "# ## GPU Acceleration Pre-Training Hardware Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dae7341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "Num GPUs Available:  1\n",
      "GPU(s) configured: ['/physical_device:GPU:0']\n",
      "Mixed precision disabled: float32\n"
     ]
    }
   ],
   "source": [
    "# GPU Configuration (safe defaults)\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# --- Toggles (use these if your GPU/driver supports them) ---\n",
    "USE_MIXED_PRECISION = False   # set True for faster training on supported GPUs\n",
    "USE_XLA = False               # set True to enable XLA (jit_compile) - can cause \"illegal access\" on some setups\n",
    "\n",
    "# Enable memory growth to prevent TensorFlow from allocating all GPU memory at once\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"GPU(s) configured: {[gpu.name for gpu in gpus]}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU found, running on CPU\")\n",
    "\n",
    "# Mixed precision (optional)\n",
    "if USE_MIXED_PRECISION:\n",
    "    mixed_precision.set_global_policy('mixed_float16')\n",
    "    print(\"Mixed precision enabled: mixed_float16\")\n",
    "else:\n",
    "    mixed_precision.set_global_policy('float32')\n",
    "    print(\"Mixed precision disabled: float32\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec4bcb2",
   "metadata": {},
   "source": [
    "# ## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edaec833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Memory-Efficient Data Preprocessing (Chunked CSV → HDF5)\n",
    "input_csv = \"Dataset/mergedCRDataset.csv\"\n",
    "preprocessed_hdf5_file = \"Dataset/Preprocessed/london_crime_data.h5\"\n",
    "os.makedirs(os.path.dirname(preprocessed_hdf5_file), exist_ok=True)\n",
    "\n",
    "chunksize = 1_000_000\n",
    "chunk_idx = 0\n",
    "\n",
    "numeric_cols = ['Longitude', 'Latitude']\n",
    "categorical_cols = ['Reported by', 'Falls within']\n",
    "target_col = 'Crime type'\n",
    "group_col = 'LSOA name'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8696d6",
   "metadata": {},
   "source": [
    "Class Defnition and Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "291c3088",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiveRAMPlot(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, max_points=100):\n",
    "        self.ram = deque(maxlen=max_points)\n",
    "        self.t = deque(maxlen=max_points)\n",
    "        self.start = time.time()\n",
    "\n",
    "        plt.ion()\n",
    "        self.fig, self.ax = plt.subplots(figsize=(8, 4))\n",
    "        self.line, = self.ax.plot([], [], linewidth=2)\n",
    "        self.ax.set_title(\"Live RAM Usage\")\n",
    "        self.ax.set_ylabel(\"GB Used\")\n",
    "        self.ax.set_xlabel(\"Time (s)\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        mem = psutil.virtual_memory()\n",
    "        self.ram.append(mem.used / (1024**3))\n",
    "        self.t.append(time.time() - self.start)\n",
    "\n",
    "        self.line.set_data(self.t, self.ram)\n",
    "        self.ax.relim()\n",
    "        self.ax.autoscale_view()\n",
    "        plt.pause(0.1)\n",
    "\n",
    "\n",
    "class LondonCrimePreprocessor:\n",
    "    \n",
    "    ## - Drops leakage / non-informative columns\n",
    "    ## - Drops rows with missing target\n",
    "    ## - Imputes numeric NaNs (per-chunk median)\n",
    "    ## - Encodes categorical + target using persistent dictionaries (no sklearn needed)\n",
    "    ## - Writes incrementally to HDF5 to avoid holding the full dataset in RAM\n",
    "    ## - Saves encoder mappings for future deployment/inference\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_csv: str,\n",
    "        hdf5_path: str,\n",
    "        encoders_path: str,\n",
    "        numeric_cols: list,\n",
    "        categorical_cols: list,\n",
    "        target_col: str,\n",
    "        drop_cols: list,\n",
    "        sep: str = \"\\t\",\n",
    "        chunksize: int = 1_000_000,\n",
    "        on_bad_lines: str = \"skip\",\n",
    "        engine: str = \"python\",\n",
    "        verbose: bool = True,\n",
    "    ):\n",
    "        self.input_csv = input_csv\n",
    "        self.hdf5_path = hdf5_path\n",
    "        self.encoders_path = encoders_path\n",
    "        self.numeric_cols = numeric_cols\n",
    "        self.categorical_cols = categorical_cols\n",
    "        self.target_col = target_col\n",
    "        self.drop_cols = drop_cols\n",
    "        self.sep = sep\n",
    "        self.chunksize = chunksize\n",
    "        self.on_bad_lines = on_bad_lines\n",
    "        self.engine = engine\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # dict encoders: {col: {category_string: int_id}}\n",
    "        self.cat_maps = {c: {} for c in self.categorical_cols}\n",
    "        self.target_map = {}  # {target_string: int_id}\n",
    "\n",
    "    def _encode_series(self, s: pd.Series, mapping: dict) -> np.ndarray:\n",
    "        # Ensure string + handle missing\n",
    "        s = s.astype(\"string\").fillna(\"Unknown\")\n",
    "        out = np.empty(len(s), dtype=np.int32)\n",
    "\n",
    "        # Fast path: use map then fill for unseen\n",
    "        mapped = s.map(mapping)\n",
    "        unseen_mask = mapped.isna()\n",
    "\n",
    "        if unseen_mask.any():\n",
    "            unseen_vals = s[unseen_mask].unique().tolist()\n",
    "            start = len(mapping)\n",
    "            for i, v in enumerate(unseen_vals):\n",
    "                mapping[str(v)] = start + i\n",
    "            mapped = s.map(mapping)\n",
    "\n",
    "        out[:] = mapped.astype(np.int32).to_numpy()\n",
    "        return out\n",
    "\n",
    "    def preprocess(self):\n",
    "        os.makedirs(os.path.dirname(self.hdf5_path), exist_ok=True)\n",
    "        os.makedirs(os.path.dirname(self.encoders_path), exist_ok=True)\n",
    "\n",
    "        n_features = len(self.numeric_cols) + len(self.categorical_cols)\n",
    "\n",
    "        if os.path.exists(self.hdf5_path):\n",
    "            if self.verbose:\n",
    "                print(f\"✓ Preprocessed data already exists at {self.hdf5_path}\")\n",
    "                print(\"Skipping preprocessing... Loading from file.\")\n",
    "            return\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"Preprocessing dataset and saving to {self.hdf5_path}...\")\n",
    "\n",
    "        with h5py.File(self.hdf5_path, \"w\") as h5:\n",
    "            X_ds = h5.create_dataset(\n",
    "                \"X\",\n",
    "                shape=(0, n_features),\n",
    "                maxshape=(None, n_features),\n",
    "                dtype=\"float32\",\n",
    "                chunks=True,\n",
    "            )\n",
    "            y_ds = h5.create_dataset(\n",
    "                \"y\",\n",
    "                shape=(0,),\n",
    "                maxshape=(None,),\n",
    "                dtype=\"int32\",\n",
    "                chunks=True,\n",
    "            )\n",
    "\n",
    "            total_rows = 0\n",
    "            chunk_idx = 0\n",
    "\n",
    "            for chunk in pd.read_csv(\n",
    "                self.input_csv,\n",
    "                sep=self.sep,\n",
    "                engine=self.engine,\n",
    "                on_bad_lines=self.on_bad_lines,\n",
    "                chunksize=self.chunksize,\n",
    "            ):\n",
    "                chunk_idx += 1\n",
    "                chunk.columns = chunk.columns.str.strip()\n",
    "\n",
    "                # Drop duplicates\n",
    "                chunk.drop_duplicates(inplace=True)\n",
    "\n",
    "                # Drop leakage / noise cols (if present)\n",
    "                chunk.drop(columns=self.drop_cols, inplace=True, errors=\"ignore\")\n",
    "\n",
    "                # Drop rows missing the target\n",
    "                if self.target_col not in chunk.columns:\n",
    "                    if self.verbose:\n",
    "                        print(f\"[!] Chunk {chunk_idx}: target column '{self.target_col}' not found. Skipping chunk.\")\n",
    "                    continue\n",
    "                chunk = chunk.dropna(subset=[self.target_col])\n",
    "\n",
    "                # Keep only required columns\n",
    "                keep_cols = [c for c in (self.numeric_cols + self.categorical_cols + [self.target_col]) if c in chunk.columns]\n",
    "                chunk = chunk[keep_cols].copy()\n",
    "\n",
    "                # Numeric imputation (per-chunk median)\n",
    "                for col in self.numeric_cols:\n",
    "                    if col in chunk.columns:\n",
    "                        med = chunk[col].median()\n",
    "                        chunk[col] = chunk[col].fillna(med)\n",
    "\n",
    "                # Fill categorical missing with Unknown\n",
    "                for col in self.categorical_cols:\n",
    "                    if col in chunk.columns:\n",
    "                        chunk[col] = chunk[col].astype(\"string\").fillna(\"Unknown\")\n",
    "\n",
    "                # --- Monitoring summary ---\n",
    "                if self.verbose:\n",
    "                    summary = pd.DataFrame({\n",
    "                        \"missing\": chunk.isna().sum(),\n",
    "                        \"non_missing\": chunk.notna().sum(),\n",
    "                        \"total\": len(chunk)\n",
    "                    })\n",
    "                    print(f\"\\nChunk {chunk_idx} summary:\")\n",
    "                    print(summary)\n",
    "\n",
    "                # Encode features\n",
    "                X_parts = []\n",
    "\n",
    "                # numeric\n",
    "                for col in self.numeric_cols:\n",
    "                    if col in chunk.columns:\n",
    "                        X_parts.append(chunk[col].to_numpy(dtype=np.float32))\n",
    "                    else:\n",
    "                        # if missing in file, fill with zeros\n",
    "                        X_parts.append(np.zeros(len(chunk), dtype=np.float32))\n",
    "\n",
    "                # categorical\n",
    "                for col in self.categorical_cols:\n",
    "                    if col in chunk.columns:\n",
    "                        enc = self._encode_series(chunk[col], self.cat_maps[col]).astype(np.float32)\n",
    "                        X_parts.append(enc)\n",
    "                    else:\n",
    "                        X_parts.append(np.zeros(len(chunk), dtype=np.float32))\n",
    "\n",
    "                X_chunk = np.stack(X_parts, axis=1).astype(np.float32)\n",
    "\n",
    "                # Encode target\n",
    "                y_enc = self._encode_series(chunk[self.target_col], self.target_map)\n",
    "\n",
    "                # Append to HDF5 (resize)\n",
    "                new_total = total_rows + len(chunk)\n",
    "                X_ds.resize((new_total, n_features))\n",
    "                y_ds.resize((new_total,))\n",
    "\n",
    "                X_ds[total_rows:new_total, :] = X_chunk\n",
    "                y_ds[total_rows:new_total] = y_enc\n",
    "\n",
    "                total_rows = new_total\n",
    "\n",
    "                if self.verbose:\n",
    "                    print(f\"Chunk {chunk_idx} target value counts (top 10):\")\n",
    "                    print(chunk[self.target_col].value_counts().head(10))\n",
    "                    print(f\"[✓] Appended {len(chunk):,} rows. Total so far: {total_rows:,}\")\n",
    "\n",
    "            if self.verbose:\n",
    "                print(f\"\\nTotal number of samples saved: {total_rows:,}\")\n",
    "\n",
    "        # Save encoders for deployment\n",
    "        encoders = {\n",
    "            \"categorical_maps\": self.cat_maps,\n",
    "            \"target_map\": self.target_map,\n",
    "            \"numeric_cols\": self.numeric_cols,\n",
    "            \"categorical_cols\": self.categorical_cols,\n",
    "            \"target_col\": self.target_col,\n",
    "            \"drop_cols\": self.drop_cols,\n",
    "        }\n",
    "        with open(self.encoders_path, \"wb\") as f:\n",
    "            pickle.dump(encoders, f)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"✓ Preprocessing complete! Data saved to HDF5.\")\n",
    "            print(f\"✓ Encoder mappings saved to: {self.encoders_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8f2baa",
   "metadata": {},
   "source": [
    "# ## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c271737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing dataset and saving to Dataset/Preprocessed/london_crime_data.h5...\n",
      "\n",
      "Chunk 1 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       648975  648975\n",
      "Latitude            0       648975  648975\n",
      "Reported by         0       648975  648975\n",
      "Falls within        0       648975  648975\n",
      "Crime type          0       648975  648975\n",
      "Chunk 1 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    239049\n",
      "Anti-social behaviour            71511\n",
      "Public order                     58456\n",
      "Criminal damage and arson        55822\n",
      "Other theft                      52460\n",
      "Vehicle crime                    43717\n",
      "Shoplifting                      35943\n",
      "Burglary                         28843\n",
      "Drugs                            18164\n",
      "Other crime                      12164\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 648,975 rows. Total so far: 648,975\n",
      "\n",
      "Chunk 2 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       595274  595274\n",
      "Latitude            0       595274  595274\n",
      "Reported by         0       595274  595274\n",
      "Falls within        0       595274  595274\n",
      "Crime type          0       595274  595274\n",
      "Chunk 2 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    213590\n",
      "Anti-social behaviour            58943\n",
      "Other theft                      57025\n",
      "Criminal damage and arson        48256\n",
      "Public order                     47840\n",
      "Vehicle crime                    44133\n",
      "Shoplifting                      30971\n",
      "Burglary                         28656\n",
      "Drugs                            19180\n",
      "Theft from the person            16030\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 595,274 rows. Total so far: 1,244,249\n",
      "\n",
      "Chunk 3 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       545858  545858\n",
      "Latitude            0       545858  545858\n",
      "Reported by         0       545858  545858\n",
      "Falls within        0       545858  545858\n",
      "Crime type          0       545858  545858\n",
      "Chunk 3 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    204534\n",
      "Anti-social behaviour            54835\n",
      "Criminal damage and arson        46066\n",
      "Other theft                      45919\n",
      "Public order                     42981\n",
      "Vehicle crime                    37465\n",
      "Shoplifting                      33752\n",
      "Burglary                         26643\n",
      "Drugs                            17105\n",
      "Other crime                      11330\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 545,858 rows. Total so far: 1,790,107\n",
      "\n",
      "Chunk 4 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       534235  534235\n",
      "Latitude            0       534235  534235\n",
      "Reported by         0       534235  534235\n",
      "Falls within        0       534235  534235\n",
      "Crime type          0       534235  534235\n",
      "Chunk 4 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    197907\n",
      "Anti-social behaviour            52359\n",
      "Criminal damage and arson        44739\n",
      "Public order                     44473\n",
      "Other theft                      43185\n",
      "Vehicle crime                    37226\n",
      "Shoplifting                      36357\n",
      "Burglary                         25229\n",
      "Drugs                            14867\n",
      "Other crime                      10709\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 534,235 rows. Total so far: 2,324,342\n",
      "\n",
      "Chunk 5 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       553143  553143\n",
      "Latitude            0       553143  553143\n",
      "Reported by         0       553143  553143\n",
      "Falls within        0       553143  553143\n",
      "Crime type          0       553143  553143\n",
      "Chunk 5 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    205440\n",
      "Anti-social behaviour            54934\n",
      "Public order                     48553\n",
      "Criminal damage and arson        45716\n",
      "Other theft                      45115\n",
      "Shoplifting                      38729\n",
      "Vehicle crime                    35474\n",
      "Burglary                         24123\n",
      "Drugs                            15961\n",
      "Other crime                      11533\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 553,143 rows. Total so far: 2,877,485\n",
      "\n",
      "Chunk 6 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       537725  537725\n",
      "Latitude            0       537725  537725\n",
      "Reported by         0       537725  537725\n",
      "Falls within        0       537725  537725\n",
      "Crime type          0       537725  537725\n",
      "Chunk 6 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    195096\n",
      "Anti-social behaviour            64284\n",
      "Public order                     47466\n",
      "Criminal damage and arson        46473\n",
      "Other theft                      41878\n",
      "Shoplifting                      36970\n",
      "Vehicle crime                    32256\n",
      "Burglary                         22151\n",
      "Drugs                            14916\n",
      "Other crime                      10158\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 537,725 rows. Total so far: 3,415,210\n",
      "\n",
      "Chunk 7 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       534414  534414\n",
      "Latitude            0       534414  534414\n",
      "Reported by         0       534414  534414\n",
      "Falls within        0       534414  534414\n",
      "Crime type          0       534414  534414\n",
      "Chunk 7 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    195803\n",
      "Anti-social behaviour            66621\n",
      "Public order                     45244\n",
      "Criminal damage and arson        44053\n",
      "Other theft                      42653\n",
      "Shoplifting                      35356\n",
      "Vehicle crime                    31144\n",
      "Burglary                         21262\n",
      "Drugs                            15007\n",
      "Other crime                      10404\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 534,414 rows. Total so far: 3,949,624\n",
      "\n",
      "Chunk 8 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       534591  534591\n",
      "Latitude            0       534591  534591\n",
      "Reported by         0       534591  534591\n",
      "Falls within        0       534591  534591\n",
      "Crime type          0       534591  534591\n",
      "Chunk 8 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    193736\n",
      "Anti-social behaviour            67887\n",
      "Criminal damage and arson        43485\n",
      "Other theft                      43414\n",
      "Public order                     43388\n",
      "Shoplifting                      37276\n",
      "Vehicle crime                    31207\n",
      "Burglary                         21183\n",
      "Drugs                            14951\n",
      "Other crime                      10123\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 534,591 rows. Total so far: 4,484,215\n",
      "\n",
      "Chunk 9 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       527041  527041\n",
      "Latitude            0       527041  527041\n",
      "Reported by         0       527041  527041\n",
      "Falls within        0       527041  527041\n",
      "Crime type          0       527041  527041\n",
      "Chunk 9 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    186491\n",
      "Anti-social behaviour            65195\n",
      "Other theft                      44151\n",
      "Criminal damage and arson        44056\n",
      "Shoplifting                      40774\n",
      "Public order                     40622\n",
      "Vehicle crime                    31875\n",
      "Burglary                         22001\n",
      "Drugs                            15273\n",
      "Other crime                       9587\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 527,041 rows. Total so far: 5,011,256\n",
      "\n",
      "Chunk 10 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       516098  516098\n",
      "Latitude            0       516098  516098\n",
      "Reported by         0       516098  516098\n",
      "Falls within        0       516098  516098\n",
      "Crime type          0       516098  516098\n",
      "Chunk 10 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    182829\n",
      "Anti-social behaviour            65243\n",
      "Criminal damage and arson        42678\n",
      "Other theft                      41557\n",
      "Public order                     39904\n",
      "Shoplifting                      39590\n",
      "Vehicle crime                    31888\n",
      "Burglary                         22265\n",
      "Drugs                            15015\n",
      "Other crime                       9526\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 516,098 rows. Total so far: 5,527,354\n",
      "\n",
      "Chunk 11 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       499740  499740\n",
      "Latitude            0       499740  499740\n",
      "Reported by         0       499740  499740\n",
      "Falls within        0       499740  499740\n",
      "Crime type          0       499740  499740\n",
      "Chunk 11 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    180352\n",
      "Anti-social behaviour            59104\n",
      "Criminal damage and arson        41210\n",
      "Other theft                      39545\n",
      "Public order                     39419\n",
      "Shoplifting                      37008\n",
      "Vehicle crime                    31754\n",
      "Burglary                         21551\n",
      "Drugs                            14645\n",
      "Other crime                       9326\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 499,740 rows. Total so far: 6,027,094\n",
      "\n",
      "Chunk 12 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       481804  481804\n",
      "Latitude            0       481804  481804\n",
      "Reported by         0       481804  481804\n",
      "Falls within        0       481804  481804\n",
      "Crime type          0       481804  481804\n",
      "Chunk 12 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    172249\n",
      "Anti-social behaviour            52843\n",
      "Other theft                      40459\n",
      "Criminal damage and arson        39942\n",
      "Shoplifting                      36542\n",
      "Public order                     35447\n",
      "Vehicle crime                    32725\n",
      "Burglary                         21865\n",
      "Drugs                            14003\n",
      "Theft from the person            10024\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 481,804 rows. Total so far: 6,508,898\n",
      "\n",
      "Chunk 13 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       482446  482446\n",
      "Latitude            0       482446  482446\n",
      "Reported by         0       482446  482446\n",
      "Falls within        0       482446  482446\n",
      "Crime type          0       482446  482446\n",
      "Chunk 13 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    174647\n",
      "Anti-social behaviour            48454\n",
      "Other theft                      42207\n",
      "Criminal damage and arson        38984\n",
      "Shoplifting                      35106\n",
      "Vehicle crime                    33514\n",
      "Public order                     33474\n",
      "Burglary                         23337\n",
      "Drugs                            14677\n",
      "Theft from the person            12983\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 482,446 rows. Total so far: 6,991,344\n",
      "\n",
      "Chunk 14 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       532456  532456\n",
      "Latitude            0       532456  532456\n",
      "Reported by         0       532456  532456\n",
      "Falls within        0       532456  532456\n",
      "Crime type          0       532456  532456\n",
      "Chunk 14 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    192999\n",
      "Anti-social behaviour            54101\n",
      "Other theft                      46635\n",
      "Criminal damage and arson        41581\n",
      "Shoplifting                      39331\n",
      "Vehicle crime                    36455\n",
      "Public order                     33686\n",
      "Burglary                         26531\n",
      "Theft from the person            16702\n",
      "Drugs                            16457\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 532,456 rows. Total so far: 7,523,800\n",
      "\n",
      "Chunk 15 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       515621  515621\n",
      "Latitude            0       515621  515621\n",
      "Reported by         0       515621  515621\n",
      "Falls within        0       515621  515621\n",
      "Crime type          0       515621  515621\n",
      "Chunk 15 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    188906\n",
      "Anti-social behaviour            54516\n",
      "Shoplifting                      43127\n",
      "Criminal damage and arson        41842\n",
      "Other theft                      40418\n",
      "Public order                     36305\n",
      "Vehicle crime                    33165\n",
      "Burglary                         23345\n",
      "Drugs                            15913\n",
      "Theft from the person            11099\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 515,621 rows. Total so far: 8,039,421\n",
      "\n",
      "Chunk 16 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       533353  533353\n",
      "Latitude            0       533353  533353\n",
      "Reported by         0       533353  533353\n",
      "Falls within        0       533353  533353\n",
      "Crime type          0       533353  533353\n",
      "Chunk 16 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    197512\n",
      "Anti-social behaviour            56432\n",
      "Shoplifting                      43804\n",
      "Criminal damage and arson        42375\n",
      "Other theft                      39691\n",
      "Public order                     38162\n",
      "Vehicle crime                    34363\n",
      "Burglary                         23426\n",
      "Drugs                            15862\n",
      "Theft from the person            12680\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 533,353 rows. Total so far: 8,572,774\n",
      "\n",
      "Chunk 17 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       514937  514937\n",
      "Latitude            0       514937  514937\n",
      "Reported by         0       514937  514937\n",
      "Falls within        0       514937  514937\n",
      "Crime type          0       514937  514937\n",
      "Chunk 17 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    181417\n",
      "Anti-social behaviour            58725\n",
      "Shoplifting                      46856\n",
      "Criminal damage and arson        41835\n",
      "Other theft                      38689\n",
      "Public order                     37917\n",
      "Vehicle crime                    32478\n",
      "Burglary                         22250\n",
      "Drugs                            14477\n",
      "Theft from the person            12194\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 514,937 rows. Total so far: 9,087,711\n",
      "\n",
      "Chunk 18 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       529490  529490\n",
      "Latitude            0       529490  529490\n",
      "Reported by         0       529490  529490\n",
      "Falls within        0       529490  529490\n",
      "Crime type          0       529490  529490\n",
      "Chunk 18 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    192860\n",
      "Anti-social behaviour            65524\n",
      "Shoplifting                      42782\n",
      "Criminal damage and arson        42019\n",
      "Public order                     41676\n",
      "Other theft                      38723\n",
      "Vehicle crime                    30018\n",
      "Burglary                         20251\n",
      "Drugs                            15389\n",
      "Other crime                      11799\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 529,490 rows. Total so far: 9,617,201\n",
      "\n",
      "Chunk 19 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       533979  533979\n",
      "Latitude            0       533979  533979\n",
      "Reported by         0       533979  533979\n",
      "Falls within        0       533979  533979\n",
      "Crime type          0       533979  533979\n",
      "Chunk 19 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    193750\n",
      "Anti-social behaviour            66428\n",
      "Criminal damage and arson        43225\n",
      "Shoplifting                      43096\n",
      "Public order                     41567\n",
      "Other theft                      39913\n",
      "Vehicle crime                    29901\n",
      "Burglary                         20679\n",
      "Drugs                            15267\n",
      "Other crime                      11710\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 533,979 rows. Total so far: 10,151,180\n",
      "\n",
      "Chunk 20 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       527181  527181\n",
      "Latitude            0       527181  527181\n",
      "Reported by         0       527181  527181\n",
      "Falls within        0       527181  527181\n",
      "Crime type          0       527181  527181\n",
      "Chunk 20 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    187712\n",
      "Anti-social behaviour            65371\n",
      "Shoplifting                      45180\n",
      "Criminal damage and arson        42839\n",
      "Public order                     41715\n",
      "Other theft                      38939\n",
      "Vehicle crime                    29801\n",
      "Burglary                         20997\n",
      "Drugs                            15375\n",
      "Other crime                      11422\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 527,181 rows. Total so far: 10,678,361\n",
      "\n",
      "Chunk 21 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       517841  517841\n",
      "Latitude            0       517841  517841\n",
      "Reported by         0       517841  517841\n",
      "Falls within        0       517841  517841\n",
      "Crime type          0       517841  517841\n",
      "Chunk 21 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    183527\n",
      "Anti-social behaviour            63156\n",
      "Shoplifting                      47278\n",
      "Criminal damage and arson        41297\n",
      "Public order                     40737\n",
      "Other theft                      37490\n",
      "Vehicle crime                    29667\n",
      "Burglary                         20890\n",
      "Drugs                            14810\n",
      "Other crime                      11248\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 517,841 rows. Total so far: 11,196,202\n",
      "\n",
      "Chunk 22 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       502444  502444\n",
      "Latitude            0       502444  502444\n",
      "Reported by         0       502444  502444\n",
      "Falls within        0       502444  502444\n",
      "Crime type          0       502444  502444\n",
      "Chunk 22 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    179065\n",
      "Anti-social behaviour            58242\n",
      "Shoplifting                      46590\n",
      "Criminal damage and arson        39783\n",
      "Public order                     36151\n",
      "Other theft                      36025\n",
      "Vehicle crime                    30309\n",
      "Burglary                         20705\n",
      "Drugs                            16700\n",
      "Other crime                      12053\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 502,444 rows. Total so far: 11,698,646\n",
      "\n",
      "Chunk 23 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       506480  506480\n",
      "Latitude            0       506480  506480\n",
      "Reported by         0       506480  506480\n",
      "Falls within        0       506480  506480\n",
      "Crime type          0       506480  506480\n",
      "Chunk 23 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    179357\n",
      "Anti-social behaviour            56176\n",
      "Shoplifting                      47091\n",
      "Criminal damage and arson        39877\n",
      "Other theft                      36856\n",
      "Public order                     36012\n",
      "Vehicle crime                    30114\n",
      "Burglary                         21324\n",
      "Drugs                            18430\n",
      "Theft from the person            12293\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 506,480 rows. Total so far: 12,205,126\n",
      "\n",
      "Chunk 24 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       472922  472922\n",
      "Latitude            0       472922  472922\n",
      "Reported by         0       472922  472922\n",
      "Falls within        0       472922  472922\n",
      "Crime type          0       472922  472922\n",
      "Chunk 24 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    169330\n",
      "Anti-social behaviour            49677\n",
      "Shoplifting                      42189\n",
      "Other theft                      36654\n",
      "Criminal damage and arson        36265\n",
      "Public order                     31349\n",
      "Vehicle crime                    28544\n",
      "Burglary                         21112\n",
      "Drugs                            17541\n",
      "Theft from the person            14523\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 472,922 rows. Total so far: 12,678,048\n",
      "\n",
      "Chunk 25 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       529714  529714\n",
      "Latitude            0       529714  529714\n",
      "Reported by         0       529714  529714\n",
      "Falls within        0       529714  529714\n",
      "Crime type          0       529714  529714\n",
      "Chunk 25 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    189989\n",
      "Anti-social behaviour            56112\n",
      "Shoplifting                      45719\n",
      "Other theft                      41418\n",
      "Criminal damage and arson        39189\n",
      "Public order                     32690\n",
      "Vehicle crime                    31984\n",
      "Burglary                         24038\n",
      "Drugs                            21064\n",
      "Theft from the person            18491\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 529,714 rows. Total so far: 13,207,762\n",
      "\n",
      "Chunk 26 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       510763  510763\n",
      "Latitude            0       510763  510763\n",
      "Reported by         0       510763  510763\n",
      "Falls within        0       510763  510763\n",
      "Crime type          0       510763  510763\n",
      "Chunk 26 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    188404\n",
      "Anti-social behaviour            54043\n",
      "Shoplifting                      49477\n",
      "Criminal damage and arson        38862\n",
      "Other theft                      36042\n",
      "Public order                     35060\n",
      "Vehicle crime                    29057\n",
      "Burglary                         21333\n",
      "Drugs                            19581\n",
      "Other crime                      13690\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 510,763 rows. Total so far: 13,718,525\n",
      "\n",
      "Chunk 27 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       528612  528612\n",
      "Latitude            0       528612  528612\n",
      "Reported by         0       528612  528612\n",
      "Falls within        0       528612  528612\n",
      "Crime type          0       528612  528612\n",
      "Chunk 27 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    197348\n",
      "Anti-social behaviour            59520\n",
      "Shoplifting                      48596\n",
      "Criminal damage and arson        40418\n",
      "Public order                     38043\n",
      "Other theft                      35607\n",
      "Vehicle crime                    28389\n",
      "Burglary                         20257\n",
      "Drugs                            19448\n",
      "Other crime                      13757\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 528,612 rows. Total so far: 14,247,137\n",
      "\n",
      "Chunk 28 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       534048  534048\n",
      "Latitude            0       534048  534048\n",
      "Reported by         0       534048  534048\n",
      "Falls within        0       534048  534048\n",
      "Crime type          0       534048  534048\n",
      "Chunk 28 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    194368\n",
      "Anti-social behaviour            67557\n",
      "Shoplifting                      47176\n",
      "Criminal damage and arson        42497\n",
      "Public order                     39963\n",
      "Other theft                      37382\n",
      "Vehicle crime                    26631\n",
      "Drugs                            19497\n",
      "Burglary                         19010\n",
      "Other crime                      12653\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 534,048 rows. Total so far: 14,781,185\n",
      "\n",
      "Chunk 29 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       537889  537889\n",
      "Latitude            0       537889  537889\n",
      "Reported by         0       537889  537889\n",
      "Falls within        0       537889  537889\n",
      "Crime type          0       537889  537889\n",
      "Chunk 29 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    199973\n",
      "Anti-social behaviour            68261\n",
      "Shoplifting                      45547\n",
      "Criminal damage and arson        42844\n",
      "Public order                     40364\n",
      "Other theft                      36569\n",
      "Vehicle crime                    26616\n",
      "Drugs                            19519\n",
      "Burglary                         19213\n",
      "Other crime                      11527\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 537,889 rows. Total so far: 15,319,074\n",
      "\n",
      "Chunk 30 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       537036  537036\n",
      "Latitude            0       537036  537036\n",
      "Reported by         0       537036  537036\n",
      "Falls within        0       537036  537036\n",
      "Crime type          0       537036  537036\n",
      "Chunk 30 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    203322\n",
      "Anti-social behaviour            68814\n",
      "Shoplifting                      43816\n",
      "Public order                     41327\n",
      "Criminal damage and arson        41002\n",
      "Other theft                      36750\n",
      "Vehicle crime                    25648\n",
      "Burglary                         18698\n",
      "Drugs                            18575\n",
      "Other crime                      11629\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 537,036 rows. Total so far: 15,856,110\n",
      "\n",
      "Chunk 31 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       529270  529270\n",
      "Latitude            0       529270  529270\n",
      "Reported by         0       529270  529270\n",
      "Falls within        0       529270  529270\n",
      "Crime type          0       529270  529270\n",
      "Chunk 31 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    202864\n",
      "Anti-social behaviour            69452\n",
      "Shoplifting                      41311\n",
      "Criminal damage and arson        40437\n",
      "Public order                     39784\n",
      "Other theft                      35472\n",
      "Vehicle crime                    25143\n",
      "Drugs                            18393\n",
      "Burglary                         17685\n",
      "Other crime                      11019\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 529,270 rows. Total so far: 16,385,380\n",
      "\n",
      "Chunk 32 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       492853  492853\n",
      "Latitude            0       492853  492853\n",
      "Reported by         0       492853  492853\n",
      "Falls within        0       492853  492853\n",
      "Crime type          0       492853  492853\n",
      "Chunk 32 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    179311\n",
      "Anti-social behaviour            62751\n",
      "Shoplifting                      41803\n",
      "Criminal damage and arson        38705\n",
      "Public order                     37399\n",
      "Other theft                      33887\n",
      "Vehicle crime                    25752\n",
      "Drugs                            18661\n",
      "Burglary                         18236\n",
      "Other crime                      11040\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 492,853 rows. Total so far: 16,878,233\n",
      "\n",
      "Chunk 33 summary:\n",
      "              missing  non_missing   total\n",
      "Longitude           0       275652  275652\n",
      "Latitude            0       275652  275652\n",
      "Reported by         0       275652  275652\n",
      "Falls within        0       275652  275652\n",
      "Crime type          0       275652  275652\n",
      "Chunk 33 target value counts (top 10):\n",
      "Crime type\n",
      "Violence and sexual offences    96142\n",
      "Anti-social behaviour           32433\n",
      "Shoplifting                     24592\n",
      "Other theft                     20353\n",
      "Criminal damage and arson       19791\n",
      "Public order                    19384\n",
      "Vehicle crime                   17164\n",
      "Burglary                        11331\n",
      "Drugs                           10599\n",
      "Theft from the person            7094\n",
      "Name: count, dtype: int64\n",
      "[✓] Appended 275,652 rows. Total so far: 17,153,885\n",
      "\n",
      "Total number of samples saved: 17,153,885\n",
      "✓ Preprocessing complete! Data saved to HDF5.\n",
      "✓ Encoder mappings saved to: Dataset/Preprocessed/encoders.pkl\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Memory-Efficient Data Preprocessing (Chunked CSV → HDF5)\n",
    "# Only preprocess if file doesn't already exist\n",
    "\n",
    "drop_columns = [\n",
    "    \"Crime ID\"\n",
    "]\n",
    "\n",
    "encoders_path = os.path.join(os.path.dirname(preprocessed_hdf5_file), \"encoders.pkl\")\n",
    "\n",
    "preprocessor = LondonCrimePreprocessor(\n",
    "    input_csv=input_csv,\n",
    "    hdf5_path=preprocessed_hdf5_file,\n",
    "    encoders_path=encoders_path,\n",
    "    numeric_cols=numeric_cols,\n",
    "    categorical_cols=categorical_cols,\n",
    "    target_col=target_col,\n",
    "    drop_cols=drop_columns,\n",
    "    sep=\"\\t\",\n",
    "    chunksize=chunksize,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "preprocessor.preprocess()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ce122c",
   "metadata": {},
   "source": [
    "# ## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37e45b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded X shape: (17153885, 4)\n",
      "Loaded y shape: (17153885,)\n",
      "Training samples: 13723108, Testing samples: 3430777\n",
      "num_classes: 14\n",
      "y_train_oh shape: (13723108, 14)\n",
      "y_test_oh shape: (3430777, 14)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load Preprocessed Data, Train/Test Split, Scaling (NO leakage), One-Hot target\n",
    "with h5py.File(preprocessed_hdf5_file, 'r') as hdf5_file:\n",
    "    X = hdf5_file['X'][:]   # shape: (N, n_features)\n",
    "    y = hdf5_file['y'][:]   # shape: (N,)\n",
    "\n",
    "print(\"Loaded X shape:\", X.shape)\n",
    "print(\"Loaded y shape:\", y.shape)\n",
    "\n",
    "# Train-Test Split (stratify by integer labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}, Testing samples: {X_test.shape[0]}\")\n",
    "\n",
    "# Scale numeric features ONLY (fit on train, transform test)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "n_num = len(numeric_cols)\n",
    "X_train[:, :n_num] = scaler.fit_transform(X_train[:, :n_num])\n",
    "X_test[:, :n_num] = scaler.transform(X_test[:, :n_num])\n",
    "\n",
    "# Number of classes inferred from training split\n",
    "num_classes = int(np.max(y_train)) + 1\n",
    "print(\"num_classes:\", num_classes)\n",
    "\n",
    "# One-hot encode targets\n",
    "y_train_oh = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_oh = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "print(\"y_train_oh shape:\", y_train_oh.shape)\n",
    "print(\"y_test_oh shape:\", y_test_oh.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd6b2109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights:\n",
      "Class 0: 0.622\n",
      "Class 1: 0.926\n",
      "Class 2: 0.196\n",
      "Class 3: 3.378\n",
      "Class 4: 0.938\n",
      "Class 5: 5.464\n",
      "Class 6: 1.183\n",
      "Class 7: 0.889\n",
      "Class 8: 6.945\n",
      "Class 9: 1.701\n",
      "Class 10: 0.908\n",
      "Class 11: 2.247\n",
      "Class 12: 3.417\n",
      "Class 13: 7.484\n"
     ]
    }
   ],
   "source": [
    "# Class weights (handle imbalance) - use integer labels (NO argmax needed)\n",
    "\n",
    "# Get actual unique classes present in training data\n",
    "classes = np.unique(y_train.astype(np.int32))\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=classes,\n",
    "    y=y_train.astype(np.int32)\n",
    ")\n",
    "\n",
    "class_weight_dict = {int(cls): float(w) for cls, w in zip(classes, class_weights)}\n",
    "\n",
    "print(\"Class weights:\")\n",
    "for k, v in class_weight_dict.items():\n",
    "    print(f\"Class {k}: {v:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5464c5d",
   "metadata": {},
   "source": [
    "# ## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c90ce479",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1765762061.708739  154810 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21087 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:04.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">910</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)             │           \u001b[38;5;34m910\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,806</span> (38.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,806\u001b[0m (38.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,806</span> (38.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,806\u001b[0m (38.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MLP Model Definition (kept from Model Creation version; output fixed to num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Input(shape=X_train.shape[1:]))\n",
    "\n",
    "# Add L2 regularization to first dense layer\n",
    "model.add(Dense(\n",
    "    128,\n",
    "    activation='relu',\n",
    "    kernel_regularizer=l2(0.0005)   # <<< L2 penalty\n",
    "))\n",
    "\n",
    "model.add(Dense(\n",
    "    64,\n",
    "    activation='relu',\n",
    "    kernel_regularizer=l2(0.0001)   # <<< L2 penalty\n",
    "))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(\n",
    "    num_classes,\n",
    "    activation='softmax'\n",
    "))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.00001)\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Recall(name='recall'),\n",
    "        tf.keras.metrics.Precision(name='precision')\n",
    "    ],\n",
    "    jit_compile=USE_XLA  # <<< XLA compilation (optional)\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "save_path = 'Model'\n",
    "os.makedirs(save_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817c5840",
   "metadata": {},
   "source": [
    "# ## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c31541e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training to reach 10 total epochs (10 new epochs)...\n",
      "Epoch 1/10\n",
      "\u001b[1m3351/3351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0653 - loss: 3.7375 - precision: 0.0807 - recall: 0.0103"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3351/3351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - accuracy: 0.0572 - loss: 3.0449 - precision: 0.0808 - recall: 0.0025 - val_accuracy: 0.0436 - val_loss: 2.6434 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n",
      "Epoch 2/10\n",
      "\u001b[1m3351/3351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.0427 - loss: 2.6230 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0466 - val_loss: 2.6262 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n",
      "Epoch 3/10\n",
      "\u001b[1m3351/3351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.0481 - loss: 2.6109 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0580 - val_loss: 2.6161 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n",
      "Epoch 4/10\n",
      "\u001b[1m3351/3351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.0554 - loss: 2.6045 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0520 - val_loss: 2.6210 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n",
      "Epoch 5/10\n",
      "\u001b[1m3351/3351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.0565 - loss: 2.6007 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0594 - val_loss: 2.6083 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n",
      "Epoch 6/10\n",
      "\u001b[1m3351/3351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.0588 - loss: 2.5974 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0545 - val_loss: 2.6199 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n",
      "Epoch 7/10\n",
      "\u001b[1m3351/3351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.0590 - loss: 2.5943 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0578 - val_loss: 2.6088 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n",
      "Epoch 8/10\n",
      "\u001b[1m3351/3351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.0597 - loss: 2.5914 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0609 - val_loss: 2.6082 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n",
      "Epoch 9/10\n",
      "\u001b[1m3351/3351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.0608 - loss: 2.5888 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0597 - val_loss: 2.6129 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n",
      "Epoch 10/10\n",
      "\u001b[1m3351/3351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.0615 - loss: 2.5864 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0607 - val_loss: 2.6029 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Saved model at epoch 10\n",
      "\n",
      "Training to reach 25 total epochs (15 new epochs)...\n",
      "Epoch 1/15\n",
      "\u001b[1m3351/3351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.0621 - loss: 2.5842 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0644 - val_loss: 2.6015 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n",
      "Epoch 2/15\n",
      "\u001b[1m3351/3351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.0636 - loss: 2.5821 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0621 - val_loss: 2.6059 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n",
      "Epoch 3/15\n",
      "\u001b[1m3351/3351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.0649 - loss: 2.5802 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0663 - val_loss: 2.6053 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n",
      "Epoch 4/15\n",
      "\u001b[1m3351/3351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.0664 - loss: 2.5785 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0664 - val_loss: 2.6049 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n",
      "Epoch 5/15\n",
      "\u001b[1m3351/3351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.0682 - loss: 2.5769 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0709 - val_loss: 2.5971 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n",
      "Epoch 6/15\n",
      "\u001b[1m3351/3351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.0703 - loss: 2.5755 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0721 - val_loss: 2.5973 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n",
      "Epoch 7/15\n",
      "\u001b[1m3351/3351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.0720 - loss: 2.5742 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0700 - val_loss: 2.6002 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n",
      "Epoch 8/15\n",
      "\u001b[1m3351/3351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.0742 - loss: 2.5731 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0768 - val_loss: 2.5954 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n",
      "Epoch 9/15\n",
      "\u001b[1m3351/3351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.0768 - loss: 2.5721 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0787 - val_loss: 2.5979 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n",
      "Epoch 10/15\n",
      "\u001b[1m3351/3351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.0790 - loss: 2.5712 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0811 - val_loss: 2.5984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n",
      "Epoch 11/15\n",
      "\u001b[1m3351/3351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.0803 - loss: 2.5703 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0809 - val_loss: 2.5940 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n",
      "Epoch 12/15\n",
      "\u001b[1m3351/3351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.0816 - loss: 2.5696 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0840 - val_loss: 2.5937 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n",
      "Epoch 13/15\n",
      "\u001b[1m3351/3351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.0813 - loss: 2.5688 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0843 - val_loss: 2.5946 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n",
      "Epoch 14/15\n",
      "\u001b[1m3351/3351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.0805 - loss: 2.5681 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0842 - val_loss: 2.5911 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n",
      "Epoch 15/15\n",
      "\u001b[1m3351/3351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step - accuracy: 0.0799 - loss: 2.5673 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.0736 - val_loss: 2.5908 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Saved model at epoch 25\n"
     ]
    }
   ],
   "source": [
    "# Training (staged epochs) - using numpy arrays directly\n",
    "\n",
    "epoch_intervals = [10, 25]\n",
    "previous_epochs = 0\n",
    "stage_histories = {}\n",
    "\n",
    "ram_plot_cb = LiveRAMPlot()\n",
    "\n",
    "for target_epochs in epoch_intervals:\n",
    "    epochs_to_run = target_epochs - previous_epochs\n",
    "\n",
    "    print(\n",
    "        f\"\\nTraining to reach {target_epochs} total epochs \"\n",
    "        f\"({epochs_to_run} new epochs)...\"\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train_oh,\n",
    "        validation_data=(X_test, y_test_oh),\n",
    "        epochs=epochs_to_run,\n",
    "        batch_size=4096,   # adjust for your RAM/GPU (2048/4096 are common for tabular)\n",
    "        verbose=1,\n",
    "        class_weight=class_weight_dict,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=10,\n",
    "                restore_best_weights=True\n",
    "            ),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=5,\n",
    "                min_lr=1e-7\n",
    "            ),\n",
    "            ram_plot_cb\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    stage_histories[f\"up_to_{target_epochs}_epochs\"] = history.history\n",
    "\n",
    "    save_model_checkpoint(model, target_epochs, save_path=\"Model\")\n",
    "\n",
    "    previous_epochs = target_epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3eeb6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The filename must end in `.weights.h5`. Received: filepath=Model/my_model_weights.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m weights_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmy_model_weights.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39msave(model_file)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStaged training history saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhistory_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/keras/src/saving/saving_api.py:230\u001b[0m, in \u001b[0;36msave_weights\u001b[0;34m(model, filepath, overwrite, max_shard_size, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m filepath_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(filepath)\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_shard_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filepath_str\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 230\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe filename must end in `.weights.h5`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    233\u001b[0m     )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m max_shard_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filepath_str\u001b[38;5;241m.\u001b[39mendswith(\n\u001b[1;32m    235\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    236\u001b[0m ):\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe filename must end in `.weights.json` when `max_shard_size` is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecified. Received: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    240\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The filename must end in `.weights.h5`. Received: filepath=Model/my_model_weights.h5"
     ]
    }
   ],
   "source": [
    "# --- Save staged training history ---\n",
    "history_file = os.path.join(save_path, 'staged_training_history.pkl')\n",
    "with open(history_file, 'wb') as f:\n",
    "    pickle.dump(stage_histories, f)\n",
    "\n",
    "# --- Save the full model and weights ---\n",
    "model_file = os.path.join(save_path, 'my_model.h5')\n",
    "weights_file = os.path.join(save_path, 'my_model_weights.h5')\n",
    "\n",
    "model.save(model_file)\n",
    "model.save_weights(weights_file)\n",
    "\n",
    "print(f\"Staged training history saved to {history_file}\")\n",
    "print(f\"Model saved to {model_file}\")\n",
    "print(f\"Weights saved to {weights_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7cbb3f",
   "metadata": {},
   "source": [
    "Evaluation Defnition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e953b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Generate predictions for evaluation ---\n",
    "y_probs = model.predict(X_test)                    # Probabilities\n",
    "y_pred_classes = np.argmax(y_probs, axis=1)        # Predicted labels (ints)\n",
    "y_true_classes = y_test.astype(int)                # True labels (ints)\n",
    "\n",
    "# For compatibility with later code:\n",
    "all_true = y_true_classes\n",
    "all_preds = y_pred_classes\n",
    "all_probs = y_probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c496ad7d",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "732fbe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track loss and accuracy for visualization\n",
    "loss_across_epochs = history.history['loss']\n",
    "val_accuracy_across_epochs = history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba78f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization (example for Training Loss vs Validation Accuracy)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "epochs_range = range(1, len(loss_across_epochs) + 1)\n",
    "ax_twin = ax.twinx()\n",
    "line1 = ax.plot(epochs_range, loss_across_epochs, 'b-o', label='Training Loss', linewidth=2)\n",
    "line2 = ax_twin.plot(epochs_range, val_accuracy_across_epochs, 'g-s', label='Validation Accuracy', linewidth=2)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Loss', fontsize=12, color='b')\n",
    "ax_twin.set_ylabel('Accuracy', fontsize=12, color='g')\n",
    "ax.tick_params(axis='y', labelcolor='b')\n",
    "ax_twin.tick_params(axis='y', labelcolor='g')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_title('Training Loss vs Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "lines = line1 + line2\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax.legend(lines, labels, loc='upper left', fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf8ca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "plt.savefig('model_training_performance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d65d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions (will give a probability distribution)\n",
    "pred_hot = model.predict(X_test)\n",
    "#now pick the most likely outcome\n",
    "pred = np.argmax(pred_hot,axis=1)\n",
    "y_compare = y_test.astype(int) \n",
    "#calculate accuracy\n",
    "score = metrics.accuracy_score(y_compare, pred)\n",
    "\n",
    "print(\"Accuracy score: {}\".format(score))\n",
    "\n",
    "print(pred_hot[:5])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed00f77",
   "metadata": {},
   "source": [
    "# ## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0381b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# num_classes already computed earlier\n",
    "# num_classes = ...\n",
    "\n",
    "# --- Step 2: Classification report ---\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPREHENSIVE MODEL EVALUATION METRICS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6037ed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: F1 Scores ---\n",
    "macro_f1 = f1_score(y_true_classes, y_pred_classes, average='macro', zero_division=0)\n",
    "weighted_f1 = f1_score(y_true_classes, y_pred_classes, average='weighted', zero_division=0)\n",
    "print(f\"\\n1. F1 SCORES:\")\n",
    "print(f\"   Macro F1 (treats all classes equally): {macro_f1:.4f}\")\n",
    "print(f\"   Weighted F1 (accounts for class imbalance): {weighted_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e650dfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 4: Recall Scores ---\n",
    "macro_recall = recall_score(y_true_classes, y_pred_classes, average='macro', zero_division=0)\n",
    "weighted_recall = recall_score(y_true_classes, y_pred_classes, average='weighted', zero_division=0)\n",
    "per_class_recall = recall_score(y_true_classes, y_pred_classes, average=None, zero_division=0)\n",
    "print(f\"\\n2. RECALL SCORES (Detection Rate):\")\n",
    "print(f\"   Macro Recall: {macro_recall:.4f}\")\n",
    "print(f\"   Weighted Recall: {weighted_recall:.4f}\")\n",
    "print(f\"   Per-class Recall:\")\n",
    "for i, recall in enumerate(per_class_recall):\n",
    "    print(f\"      Class {i}: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9317db4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 5: Confusion Matrix ---\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "print(f\"\\n3. Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2e0481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 6: AUROC / ROC-AUC ---\n",
    "try:\n",
    "    if num_classes == 2:\n",
    "        auc = roc_auc_score(y_true_classes, y_probs[:, 1])\n",
    "        print(f\"\\n4. AUROC / ROC-AUC Score:\")\n",
    "        print(f\"   Binary AUC: {auc:.4f}\")\n",
    "    else:\n",
    "        macro_auc = roc_auc_score(y_true_classes, y_probs, multi_class='ovr', average='macro')\n",
    "        weighted_auc = roc_auc_score(y_true_classes, y_probs, multi_class='ovr', average='weighted')\n",
    "        print(f\"\\n4. AUROC / ROC-AUC Score:\")\n",
    "        print(f\"   Macro AUC (One-vs-Rest): {macro_auc:.4f}\")\n",
    "        print(f\"   Weighted AUC: {weighted_auc:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n4. AUROC / ROC-AUC:\")\n",
    "    print(f\"   Could not compute AUC: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e1d615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 7: Overall Accuracy ---\n",
    "accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "print(f\"\\nOverall Accuracy: {accuracy:.4f}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85ca166",
   "metadata": {},
   "source": [
    "# Data Analysis/Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72c43c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with multiple subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f715206c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Confusion Matrix Heatmap\n",
    "ax1 = axes[0, 0]\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1, cbar_kws={'label': 'Count'})\n",
    "ax1.set_title('Confusion Matrix (Raw Counts)', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('True Label', fontsize=12)\n",
    "ax1.set_xlabel('Predicted Label', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5254eaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional metrics visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 1. F1 Scores Comparison\n",
    "ax1 = axes[0]\n",
    "metrics = ['Macro F1', 'Weighted F1']\n",
    "scores = [macro_f1, weighted_f1]\n",
    "colors_metrics = ['#FF6B6B', '#4ECDC4']\n",
    "bars = ax1.bar(metrics, scores, color=colors_metrics, alpha=0.8, edgecolor='black', linewidth=2)\n",
    "ax1.set_ylabel('F1 Score', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('F1 Scores Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylim([0, 1])\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bar, score in zip(bars, scores):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{score:.4f}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 2. Macro Metrics Summary\n",
    "ax2 = axes[1]\n",
    "macro_precision = precision_score(all_true, all_preds, average='macro', zero_division=0)\n",
    "summary_metrics = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
    "summary_values = [accuracy, macro_precision, macro_recall, macro_f1]\n",
    "colors_summary = ['#95E1D3', '#F38181', '#AA96DA', '#FCBAD3']\n",
    "\n",
    "bars = ax2.barh(summary_metrics, summary_values, color=colors_summary, alpha=0.8, edgecolor='black', linewidth=2)\n",
    "ax2.set_xlabel('Score', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Macro-Averaged Metrics Summary', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlim([0, 1])\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "for bar, value in zip(bars, summary_values):\n",
    "    width = bar.get_width()\n",
    "    ax2.text(width, bar.get_y() + bar.get_height()/2.,\n",
    "             f'{value:.4f}', ha='left', va='center', fontsize=11, fontweight='bold', \n",
    "             bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('metrics_summary.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb94960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Normalized Confusion Matrix\n",
    "ax2 = axes[0, 1]\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='RdYlGn', ax=ax2, cbar_kws={'label': 'Recall %'})\n",
    "ax2.set_title('Confusion Matrix (Normalized by True Label)', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('True Label', fontsize=12)\n",
    "ax2.set_xlabel('Predicted Label', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e97531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Training Loss and Validation Accuracy\n",
    "ax3 = axes[1, 0]\n",
    "epochs_range = range(1, len(loss_across_epochs) + 1)\n",
    "ax3_twin = ax3.twinx()\n",
    "line1 = ax3.plot(epochs_range, loss_across_epochs, 'b-o', label='Training Loss', linewidth=2, markersize=6)\n",
    "line2 = ax3_twin.plot(epochs_range, val_accuracy_across_epochs, 'g-s', label='Validation Accuracy', linewidth=2, markersize=6)\n",
    "ax3.set_xlabel('Epoch', fontsize=12)\n",
    "ax3.set_ylabel('Loss', fontsize=12, color='b')\n",
    "ax3_twin.set_ylabel('Accuracy', fontsize=12, color='g')\n",
    "ax3.tick_params(axis='y', labelcolor='b')\n",
    "ax3_twin.tick_params(axis='y', labelcolor='g')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.set_title('Training Loss vs Validation Accuracy', fontsize=14, fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ec9353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine legends\n",
    "lines = line1 + line2\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax3.legend(lines, labels, loc='upper left', fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565c345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Per-Class Recall Bar Chart\n",
    "ax4 = axes[1, 1]\n",
    "class_names = [f'Class {i}' for i in range(len(per_class_recall))]\n",
    "colors = ['green' if r > 0.5 else 'orange' if r > 0.3 else 'red' for r in per_class_recall]\n",
    "bars = ax4.bar(class_names, per_class_recall, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "ax4.axhline(y=macro_recall, color='r', linestyle='--', linewidth=2, label=f'Macro Recall: {macro_recall:.4f}')\n",
    "ax4.set_ylabel('Recall', fontsize=12)\n",
    "ax4.set_title('Per-Class Recall (Detection Rate)', fontsize=14, fontweight='bold')\n",
    "ax4.set_ylim([0, 1])\n",
    "ax4.legend(fontsize=10)\n",
    "ax4.grid(True, alpha=0.3, axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fff683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add value labels on bars\n",
    "for bar, recall in zip(bars, per_class_recall):\n",
    "    height = bar.get_height()\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{recall:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_evaluation_metrics.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09e1a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-AUC Curves (One-vs-Rest for multi-class)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677b1773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ROC Curve (One-vs-Rest)\n",
    "ax1 = axes[0]\n",
    "if num_classes > 2:\n",
    "    # Multi-class: use label binarization\n",
    "    all_true_bin = label_binarize(all_true, classes=range(num_classes))\n",
    "    \n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, num_classes))\n",
    "    auc_scores = []\n",
    "    \n",
    "    for i in range(min(num_classes, 5)):  # Limit to 5 classes for clarity\n",
    "        fpr, tpr, _ = roc_curve(all_true_bin[:, i], all_probs[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        auc_scores.append(roc_auc)\n",
    "        ax1.plot(fpr, tpr, color=colors[i], lw=2, label=f'Class {i} (AUC = {roc_auc:.3f})')\n",
    "        # Micro-average\n",
    "        fpr, tpr, _ = roc_curve(all_true_bin.ravel(), all_probs.ravel())\n",
    "        roc_auc_micro = auc(fpr, tpr)\n",
    "        ax1.plot(fpr, tpr, color='deeppink', lw=3, linestyle=':', label=f'Micro-average (AUC = {roc_auc_micro:.3f})')\n",
    "        \n",
    "        ax1.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier')\n",
    "        ax1.set_xlim([0.0, 1.0])\n",
    "        ax1.set_ylim([0.0, 1.05])\n",
    "        ax1.set_xlabel('False Positive Rate', fontsize=11, fontweight='bold')\n",
    "        ax1.set_ylabel('True Positive Rate', fontsize=11, fontweight='bold')\n",
    "        ax1.set_title('ROC Curves (One-vs-Rest) - Top 5 Classes', fontsize=13, fontweight='bold')\n",
    "        ax1.legend(loc=\"lower right\", fontsize=9)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "else:\n",
    "    # Binary classification\n",
    "    fpr, tpr, _ = roc_curve(all_true, all_probs[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    ax1.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "    ax1.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier')\n",
    "    ax1.set_xlim([0.0, 1.0])\n",
    "    ax1.set_ylim([0.0, 1.05])\n",
    "    ax1.set_xlabel('False Positive Rate', fontsize=11, fontweight='bold')\n",
    "    ax1.set_ylabel('True Positive Rate', fontsize=11, fontweight='bold')\n",
    "    ax1.set_title('ROC Curve', fontsize=13, fontweight='bold')\n",
    "    ax1.legend(loc=\"lower right\", fontsize=10)\n",
    "    ax1.grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86385ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902e0968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Per-Class Metrics Heatmap\n",
    "ax2 = axes[1]\n",
    "precision, recall, f1, support = precision_recall_fscore_support(all_true, all_preds, \n",
    "                                                                   average=None, zero_division=0)\n",
    "\n",
    "metrics_data = np.array([precision, recall, f1]).T\n",
    "im = ax2.imshow(metrics_data, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a003090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set ticks and labels\n",
    "ax2.set_xticks([0, 1, 2])\n",
    "ax2.set_xticklabels(['Precision', 'Recall', 'F1'], fontsize=11, fontweight='bold')\n",
    "ax2.set_yticks(range(min(len(precision), 10)))\n",
    "ax2.set_yticklabels([f'Class {i}' for i in range(min(len(precision), 10))], fontsize=10)\n",
    "ax2.set_title('Per-Class Metrics Heatmap (Top 10 Classes)', fontsize=13, fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a618923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add text annotations\n",
    "for i in range(min(len(precision), 10)):\n",
    "    for j in range(3):\n",
    "        text = ax2.text(j, i, f'{metrics_data[i, j]:.2f}',\n",
    "                       ha=\"center\", va=\"center\", color=\"black\", fontsize=9, fontweight='bold')\n",
    "\n",
    "cbar = plt.colorbar(im, ax=ax2)\n",
    "cbar.set_label('Score', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('roc_and_metrics_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
