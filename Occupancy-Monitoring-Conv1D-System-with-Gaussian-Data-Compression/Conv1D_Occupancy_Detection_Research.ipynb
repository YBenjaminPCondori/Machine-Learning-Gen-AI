{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YBenjaminPCondori/Machine-Learning-Gen-AI/blob/main/Occupancy-Monitoring-Conv1D-System-with-Gaussian-Data-Compression/Conv1D_Occupancy_Detection_Research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50536fb4",
      "metadata": {
        "id": "50536fb4"
      },
      "source": [
        "# Conv1D-Based Occupancy Detection from Multisensor Time-Series Data\n",
        "\n",
        "## Abstract\n",
        "This notebook presents an end-to-end Conv1D pipeline for occupancy detection using multisensor environmental time-series data. It is structured for research, reproducibility, and publication-ready reporting."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2099058",
      "metadata": {
        "id": "e2099058"
      },
      "source": [
        "## 1. Imports and Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33b8ea21",
      "metadata": {
        "id": "33b8ea21"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report,\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, roc_auc_score, log_loss, roc_curve\n",
        ")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebaac42b",
      "metadata": {
        "id": "ebaac42b"
      },
      "source": [
        "## 2. Dataset Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d884c83c",
      "metadata": {
        "id": "d884c83c"
      },
      "outputs": [],
      "source": [
        "\n",
        "df = pd.read_csv(r\"C:/Users/ybenj/Downloads/ALL_CSVS/merged_env_motion.csv\")\n",
        "\n",
        "df.drop_duplicates(inplace=True)\n",
        "df.columns = df.columns.str.strip().str.lower()\n",
        "df = df[df['motion'].notna()]\n",
        "\n",
        "numeric_cols = df.select_dtypes(include=np.number).columns\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n",
        "\n",
        "columns_to_drop = ['smoke', 'device']\n",
        "if 'co' in df.columns:\n",
        "    columns_to_drop.append('co')\n",
        "df.drop(columns=columns_to_drop, errors='ignore', inplace=True)\n",
        "\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp']).astype('int64') / 1e9\n",
        "\n",
        "if 'light' in df.columns and df['light'].dtype == bool:\n",
        "    df['light'] = df['light'].astype(int)\n",
        "\n",
        "df.drop(columns=['hub', 'home'], inplace=True, errors='ignore')\n",
        "\n",
        "target = 'motion'\n",
        "df[target] = df[target].astype(int)\n",
        "features = [col for col in df.columns if col != target]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df[features] = scaler.fit_transform(df[features])\n",
        "\n",
        "X = df[features].values.astype(np.float32)\n",
        "y = df[target].values.astype(np.float32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b60a4c1",
      "metadata": {
        "id": "0b60a4c1"
      },
      "source": [
        "## 3. Sliding Window Construction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cc95a04",
      "metadata": {
        "id": "7cc95a04"
      },
      "outputs": [],
      "source": [
        "\n",
        "def create_windows(data, labels, window_size):\n",
        "    X_windows, y_labels = [], []\n",
        "    for i in range(len(data) - window_size):\n",
        "        X_windows.append(data[i:i+window_size])\n",
        "        y_labels.append(labels[i+window_size])\n",
        "    return np.array(X_windows), np.array(y_labels)\n",
        "\n",
        "TIME_STEPS = 100\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "X_windowed, y_windowed = create_windows(X, y, TIME_STEPS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdb2de29",
      "metadata": {
        "id": "fdb2de29"
      },
      "source": [
        "## 4. TensorFlow Dataset Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f2891c4",
      "metadata": {
        "id": "7f2891c4"
      },
      "outputs": [],
      "source": [
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X_windowed, y_windowed))\n",
        "dataset = dataset.shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "total_batches = len(list(dataset))\n",
        "train_size = int(0.8 * total_batches)\n",
        "\n",
        "train_ds = dataset.take(train_size)\n",
        "test_ds = dataset.skip(train_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e3037d4",
      "metadata": {
        "id": "3e3037d4"
      },
      "source": [
        "## 5. Class Imbalance Handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bbfa12f",
      "metadata": {
        "id": "6bbfa12f"
      },
      "outputs": [],
      "source": [
        "\n",
        "class_weights_array = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_windowed.astype(int)),\n",
        "    y=y_windowed.astype(int)\n",
        ")\n",
        "\n",
        "class_weights = dict(enumerate(class_weights_array))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b96f367",
      "metadata": {
        "id": "8b96f367"
      },
      "source": [
        "## 6. Conv1D Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "113f9b05",
      "metadata": {
        "id": "113f9b05"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(TIME_STEPS, len(features))),\n",
        "    tf.keras.layers.Conv1D(64, 3, activation='relu', padding='same'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling1D(2),\n",
        "\n",
        "    tf.keras.layers.Conv1D(128, 3, activation='relu', padding='same'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling1D(2),\n",
        "\n",
        "    tf.keras.layers.Conv1D(256, 3, activation='relu', padding='same'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling1D(2),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eeb85a07",
      "metadata": {
        "id": "eeb85a07"
      },
      "source": [
        "## 7. Training with Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a649703",
      "metadata": {
        "id": "2a649703"
      },
      "outputs": [],
      "source": [
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=10,\n",
        "    validation_data=test_ds,\n",
        "    callbacks=[early_stop],\n",
        "    class_weight=class_weights\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dae46065",
      "metadata": {
        "id": "dae46065"
      },
      "source": [
        "## 8. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1f04a08",
      "metadata": {
        "id": "b1f04a08"
      },
      "outputs": [],
      "source": [
        "\n",
        "loss, accuracy = model.evaluate(test_ds)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bbad84e",
      "metadata": {
        "id": "3bbad84e"
      },
      "source": [
        "## 9. Metrics and Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92d42bca",
      "metadata": {
        "id": "92d42bca"
      },
      "outputs": [],
      "source": [
        "\n",
        "y_true, y_pred_probs, y_pred_classes = [], [], []\n",
        "\n",
        "for x_batch, y_batch in test_ds:\n",
        "    preds = model.predict(x_batch).flatten()\n",
        "    y_true.extend(y_batch.numpy())\n",
        "    y_pred_probs.extend(preds)\n",
        "    y_pred_classes.extend((preds > 0.5).astype(int))\n",
        "\n",
        "y_true = np.array(y_true).astype(int)\n",
        "y_pred_probs = np.array(y_pred_probs)\n",
        "y_pred_classes = np.array(y_pred_classes)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}